{"meta":{"title":"Down to the Rabbit Hole","subtitle":"放映机 方向键 二进制 多巴胺","description":null,"author":"crvdgc","url":"http://crvdgc.me"},"pages":[{"title":"about","date":"2018-07-24T09:51:30.000Z","updated":"2018-07-28T17:39:28.150Z","comments":true,"path":"about/index.html","permalink":"http://crvdgc.me/about/index.html","excerpt":"","text":"Down to the Rabbit Hole兔子洞中到底有什么呢？ 这是一个科幻＋计算机爱好者的小站。 关注二进制、放映机、方向键和多巴胺的一切。 联系方式 Github: https://www.github.com/crvdgc/ 微信: yokis1997 邮件（推荐）: yokis1997@pku.edu.cn 友情链接： 微信公众号： 老火箭酒吧 laorocketbar"}],"posts":[{"title":"论文解读 Recurrent neural network based language model","slug":"rnnlm","date":"2018-07-31T10:38:18.000Z","updated":"2018-08-01T06:43:26.118Z","comments":true,"path":"2018/07/31/rnnlm/","link":"","permalink":"http://crvdgc.me/2018/07/31/rnnlm/","excerpt":"","text":"Annotation: Recurrent neural network based language model ¶作者 Tomas Mikolov Martin Karafiat Lukas Burget Jan “Honza” Cernock Sanjeev Khudanpur ¶摘要 块引用表示评论。 本文提出了一个基于 RNN 的语言模型（RNN LM）。实验表明与 backoff 语言模型相比，困惑度（perplexity）可能下降 50% 。 简单直接提出 RNN LM ，使用大量实验证明和 n-gram 相比效果不错（缺点是训练复杂度比较高）。 由于模型比较简单，因此在最后的评论中直接概括一下。这篇论文的引言写得十分精彩，对问题的分析一针见血。（当然说得这么坚定也有实验效果撑着呢，想必下笔的时候也是激动万分。）我十分喜欢，主要呈现一下这部分。 ¶引言 构建语言模型，就是处理序列预测问题（sequential data prediction）。然而，很多自然语言方法都针对于特定的语言领域（very specific for language domain）：假设自然语言可以使用分析树（parse tree）来表示，需要考虑词的形态学（morphology）、语法和语义。即使是基于 n-gram 的最通用的模型，也进行了假设：语言是由原子性的符号（也就是单词）序列（也就是句子）所组成的。句子的结尾起着十分重要且特殊的作用。 特定于语言领域这个观察十分有道理。 n-gram 以句子为单位本身已经带有很强的假设，给予了“句子”一个很高的地位，因此也就无法对句间关系建模。然而衡量语言模型好像没有不用句子假设的，即使是下面提出的 RNN 也是如此。这一段可能是为了反衬 RNN 的泛用性。 对简单的 n-gram 研究到底有没有取得显著进步，值得怀疑。如果从序列预测数据的角度来看，的确取得了很大进步。主要靠 cache models （描述长语境信息）和 class-based models （通过相似词之间共享参数改进短语境的参数估计）。其他进步大多能归结到这两类的效果上。 如果从实际应用的角度来看，那么几乎没有进展。真实世界中的语音识别和机器翻译的系统都是建立在大量的数据上的，一种流行的说法是我们只需要更多的数据就够了。学术界的模型通常很复杂并且仅仅在基于数量十分有限的数据集上效果才好。事实上，大多数的先进技术只比简单的 baseline 提高了一点，且很少在实际中使用。 满满的即视感。不过 RNN 带来的提升的确离现实应用近了一大步。 ¶评论 ¶模型 本篇的模型十分朴素，是一个简单的三层 RNN 。Token 使用的是 one-hot 编码。输入层使用单词编码和隐藏层进行拼接。隐藏层使用 sigmoid 激活函数，输出层使用 softmax 。训练算法是 truncated backpropagation through time ， SGD 。如果没有明显改善，学习率每个 epoch 减半。 ¶Dynamic 模型中一个比较有趣的地方（也是读这篇论文的原因）是使用了 dynamic 的方法。主要区别于传统的 static 方法。Static 指的是模型在训练阶段结束之后，将参数固定，在测试过程中不再改变。Dynamic 方法则是在测试时，利用训练的真实标签继续更新参数。 这种做法的一个结果是不再显式地区分训练集与测试集，因为所有的数据都只处理一次。 (Graves, 2013)[1] 中指出了 dynamic evaluation 比本篇论文报告的效果更好。 作者指出，效果和 cache 类似，但由于其在连续空间中学习，如果两个词之间联系比较紧密，那么测试数据中一个单词的频繁出现也会提高另一个单词出现概率。 另一篇专注研究 dynamic evaluation 的论文解读请看 。 ¶全文 作者认为 RNN 相比于 Bengio [3][1] 中的 FNN 的主要优势在于没有指定固定的语境，而是使用隐藏层的状态概括之前所有的语境信息。优点包括需要指定的超参数数量少，通用性强。缺点是难以捕捉长依赖问题，早在 1994 年的 [6][1] 中就已经指出了。解读请看这篇博客。 本篇将 RNN LM 引入 NLP ，使用的是最朴素的模型（本文发表于 2010 年）。实验发现其效果远好于（各种） n-gram 。（从之后的发展来看，几乎将 n-gram 送入历史的废纸堆了）。这一巨大的提升，打破了语言模型是关于各种 n-gram 以及只要有大量的数据就可以提升效果的神话。（结果现在出现了各种复杂的神经网络模型，以及只要有大量数据就可以提升效果的神话x） Yoshua Bengio and Patrice Simard and Paolo Frasconi. Learning Long-Term Dependencies with Gradient Descent is Difficult. IEEE Transactions on Neural Networks, 5, 157-166. ↩ ↩ ↩","categories":[{"name":"计算机","slug":"计算机","permalink":"http://crvdgc.me/categories/计算机/"},{"name":"人工智能","slug":"计算机/人工智能","permalink":"http://crvdgc.me/categories/计算机/人工智能/"}],"tags":[{"name":"RNN","slug":"RNN","permalink":"http://crvdgc.me/tags/RNN/"},{"name":"NLP","slug":"NLP","permalink":"http://crvdgc.me/tags/NLP/"}]},{"title":"论文解读 Learning Long-Term Dependencies with Gradient Descent is Difficult","slug":"learning-long-term","date":"2018-07-30T10:34:49.000Z","updated":"2018-07-30T10:43:46.664Z","comments":true,"path":"2018/07/30/learning-long-term/","link":"","permalink":"http://crvdgc.me/2018/07/30/learning-long-term/","excerpt":"","text":"作者Yoshua Bengio, Patrice Simard, and Paolo Frasconi 以下介绍中，块引用代表评论。 摘要指出了 RNN 所面临的问题： temporal contingencies present in the input/output sequences span intervals ，也就是所谓的长依赖问题（long-term dependencies）。接下来指出问题的原因是基于梯度的训练方法。这种方法中存在 trade-off bbetween efficient learning by gradient descent and latching on information for long periods 。 基于此提出的解决方法是使用 alternatives to standard gradient descent ，也就是标准梯度下降外的替代品。 即使作为反向传播算法的提出者， Geoffrey Hinton 在 2017 年也对该算法提出了怀疑。不过近期又发了一篇 Assessing the Scalability of Biologically-Motivated Deep Learning Algorithms and Architectures ，在一些需要特殊网络结构的数据集上比较了生物学启发的多种训练算法，结果发现效果还是 BP 不好。这篇 1994 年的文章讲了 BP 如何不适合解决序列问题中的长依赖。值得一读。 引言序列任务中需要系统能够存储、更新信息。从过去输入中计算得到的信息，对于输出是很有用的。 RNN 很适合这样的任务，因为其有内部状态（internal state）可以表示这样的上下文信息（context information）。这种特性来自于结构上的“循环”，静态的神经网络，即使引入延迟（Time Delay Neural Networks）也只能将信息储存特定时间长度，而不能储存不定时间长度。 RNN 的训练算法基于损失函数的梯度下降。比如 back-propagation through time (BPTT) 算法。 Forward propagation (FP) 算法计算代价更高，但可以在线学习。另一个训练受限 RNN 的算法中，动态神经元（dynamic neurons，只有向自己的一个反馈）和 FP 一样在时间上只需要本地信息，但权重更新所需计算只正比于权值数（和 BP 一样）。但其对于一般序列的存储能力有限，因此限制了其表示能力。 Long-term dependencies 的定义是在时间 t 的输出依赖于一个更早时间的 $\\tau \\ll t$ 。尽管 RNN 的表现超过很多统计网络，但更难训练到最优。局部最优的原因是次优解将短期依赖纳入了考虑，但没有考虑长期依赖。 Mozer [19] 发现反向传播很难发现长时间间隔的随机事件。本文从理论和实验上解释这个问题。 很惭愧只学过 BPTT ，对于另外两个都没有听说过。 一个含参数的动力系统（parametric dynamic system）的三个基本要求如下： 能够将信息储存任意时长 能够对抗噪声 参数可训练（训练时间合理） 定义信息锁存（information latching）为一个动力系统将特定比特的信息在状态变量中的长期存储。使用 hyperbolic attractor 的形式化定义将在 4.1 节给出。 hyperbolic attractor 本身的定义也将在第 4 节给出 文章共 5 节。第 2 节提出一个只有满足上述条件的系统才能解决的最小任务。接下来展示一个 RNN 解法，和一个负实验结果，表明梯度下降连这个简单任务都不适合。第 4 节的理论结果解释了一个系统要么稳定能够抵抗噪音，要么能使用梯度下降法高效训练，但不能同时达到。否则，在时间 t 的状态对于时间 0 的状态的导数将随 t 增大而指数减小。 因此，反向传播（以及一般的梯度下降算法）对于长序列效率低，因此不满足条件 3 。第 5 节提出了新的算法，并将其与反向传播的变体和模拟退火（simulated annealing）进行比较。使用的是输入输出依赖可以控制的简单任务。 第 2 节 说明问题的最小任务该任务是一个序列二分类问题，最终的类别只取决于前 L 个输入值。 也即类别 $\\mathcal{C}(u_1,\\dots,u_T) = \\mathcal{C}(u_1,\\dots,u_L)$ 。而整个输入序列可以具有任意长度 $T \\gg L$ 。 该任务中，长度 L 之后的输入都是不相关的噪声。因此，模型需要有效地储存信息才能解决这个问题。本次实验中， L 之后的输入是均值为 0 的高斯噪声。 上面提到第 3 个标准是可学习性，这里有两个方面：第一，处理前 L 步的输入并正确分类。第二，将信息储存在状态变量中任意时长。在这个任务中，前面的分类和后面储存的时长无关，因此一个简单的解决方法是使用一个锁存子系统（latching subsystem），接收前面分类子系统的信息作为输入。 由于我们希望结果不与特定的分类任务相关（也就是与分类子系统相独立），因此我们只关注后面的锁存系统。一个锁存系统想要处理任意输入序列，就需要能将错误传播回前面的系统，并检测到引发锁存的事件。（propagate error information to a module that feeds the latching subsystem and detects the events leading to latching） 因此，我们将上面的任务修改如下：前 L 个输入可供输入算法调参（can be tuned by the learning algorithm）， L 步之后的输入是随机的高斯噪声。目标函数是二分类（期望输出值分别是 ±0.8）的平方误差和。 经过改造后， $h_t\\ (t=1,\\dots, L)$ 代表了类别信息的计算结果。直接学习 $h_t$ 比从输入中学习参数 $\\theta$ 容易。而且如果 $h_t$ 是对应时间步的输入 $u_t$ 的带参函数的话，也即 $h_t(u_t, \\theta)$ ，代价函数对于 $h_t$ 的导数是一样的（BPTT 下）。如果因为梯度消失导致 $h_t$ 不能被训练出来的话，那作为带参函数同样训练不出来。 研究锁存子系统的方法十分巧妙。锁存子系统想要达到预期的功能，至少要能将分类结果的正误信息传播回分类子系统。也即假设最后是 1 类，至少应该有方法将其通知到分类子系统。而我们观察其能否通知的方式，就是让其在前 L 步输入处还原最终的分类结果。对于原来的任务来说，我们通过训练参数让这个结果最终在 L 步处出现。而训练的依据就是在第 L 步我们接受到了锁存子系统传播回来的正确类别的信息。 举一个例子来说明。假设原来的任务 L = 3 ，接受到一个序列 101001… ，假设标签为第 1 类。分类系统应该在接受到 101 这三个时间步时就已经得出分类标签为 1 这个结论了。接下来，锁存系统将 1 这个结果储存起来，直至第 T 步输出。 然而我们只希望关注锁存子系统。在原任务中，如果最终标签是 1 ，锁存子系统应该能反向传播到第 3 个时间步，告诉分类子系统标签是 1 。因此，假如序列最终的标签是 1 ，我们希望无论前 3 个输入是什么，都能得到这一标签。所以锁存子系统只需要把真实标签传播给前 3 步的分类系统即可。假如没有分类系统，我们就让锁存子系统在前 3 个位置还原最终的标签。 也就是，假设序列的最终标签是 1 （对应目标值 0.8），锁存子系统应该在前 3 步输出 0.8, 0.8, 0.8 ，如果序列最终标签是 0 ，锁存子系统应该在前 3 步输出 -0.8, -0.8, -0.8 。假如我们有真的分类子系统，它应当能在这里拿到真实的标签，并据此将其与输入序列联系起来（通过调整带参函数的参数），比如 101 或者 010 等等。 个人感觉上面的切片测试方法不仅适合测试锁存，应该适合各种具有确定期望功能的子系统。举例来说，假设一个子系统需要进行 (+1) 这个运算，应当有能力对于输出 x 在输入处还原期望的输入 (x-1) ，这样才能通知前面的系统，我需要 (x-1) 。 当然这只是完成锁存或其他功能的必要条件。 关于导数相同一段，这是因为假设 h_t 仅取决于 u_t （而非其他时间步的输入），因此 h_t(u_t, \\theta) 是一个 context-free 的函数，根据求导的链式法则，对 h_t 的导数相同，而不论它是变量还是另一个变量的函数。 关于为何选取目标函数值为 0.8 ，因为 tanh 函数值域为 (-1, 1) ，而下一层的输入在 tanh(-1) = -0.76 到 tanh(1) = 0.76 之间。因此多个 tanh 单元叠加值域就在 (-0.8, 0.8) 之间。 第 3 节 一个简单的 RNN 解决方案见图 Fig. 1a. 这是一个单一神经元的 RNN ，如果 $w \\gt 1$ ，有两个吸引子 $\\pm \\bar{x}$ ，值取决于 $w$ 。 假设初值 $x_0 = -\\bar{x}$ ，文献 [7, 8] 表明存在 $h^\\star \\gt 0$ 满足： $x_t$ maintains its sign if $|h_t| \\lt h^\\star$ ，也即小于阈值的输入不会改变状态的符号。 there exists a finite number of steps $L_1$ such that $x_{L_1} \\gt \\bar{x}$ if $h_t \\gt h^\\star \\ \\forall t \\le L_1$ 。也即假如超过正向阈值的输入持续了超过 $L_1$ 步后，会在 $L_1$ 步时将状态转到正向吸引子 $\\bar{x}$ 。 对于初值为正的情况有相应的对称结论。 当 $w$ 固定， $L_1$ 随着 $|h_t|$ 的增加而减小。 据此我们可以得到： 该系统可以储存一个 bit 的信息。通过最终输出的符号确定。 存储是通过将足够强（大于 $|h^\\star|$）的输入保持足够长的时间实现的。 小的（小于 $|h^\\star|$）噪声不会影响输出的符号。无论持续时间有多长。 参数 $w$ 也是可训练的，更大的 $w$ 对应于更大的阈值 $h^\\star$ ，对抗噪声的能力也就越强。 比如可以通过调整，使得 $h^1_t \\ge H$ 且 $h^0_t \\le H$ ，其中 $H \\gt h^\\star$ 来实现。 从上面的 Fig. 1b. 我们可以看到成功学习出来了加粗部分的前 3 个 $h_t$ 。 下面看各参数的影响。 首先 Fig. 2a 是噪声的标准差 $s$ 和初始的权值 $w_0$ 的影响。我们可以看到随着 $s$ 的增大和 $w_0$ 的减小，效果变差。 这很符合我们的直觉，噪声越强，对抗噪声的阈值越低，越容易丢失存储。 Fig. 2b 展示了随着 $T$ 的增加，收敛性变差。这表明，梯度下降即使对于长时间存储 1 位信息也很困难。 第 4 节 使用动力系统学习锁存本节以基于动力系统的实时识别器为例子，说明 RNN 能够按双曲吸引子（hyperbolic attractors）的方式鲁棒性地储存信息的条件，会导致梯度消失的问题。 非自动（non-autonomous）的离散时间的系统，带有额外的输入： $$ a_t = M(a_{t-1}) + u_t $$ 和自动系统（autonomous system）： $$ a_t = M(a_{t-1})$$ 其中， $a_t$ 代表系统状态， $u_{t}$ 代表输入。两者是 $n$ 维向量， $M$ 代表非线性映射。 不带有额外输入的自动系统，可以通过引入额外状态变量和对应输入的方式，转变成非自动的系统。 比如 $a_t = N(a_{t-1}, u_{t-1})$ （ $a_t$ ， $u_t$ 分别为 $n$ 维和 $m$ 维向量）可以转化为 $a_t^\\prime = N^\\prime(a_{t-1}^\\prime) + u_t^\\prime$ ，其中 $a_{t}^\\prime = (a_t, y_t)$ 是一个 $n+m$ 维向量， $u_t^\\prime = (0, u_t)$ 即前 $n$ 个分量为 0 ，$N^\\prime(a_t^\\prime) = (N_t(a_{t-1}, y_{t-1}), 0)$ 即后 $m$ 个分量为 0 。 最终，$y_t = u_t$ 。 以上转换相当于将本来的内部状态变量当做系统的额外输入。使用映射计算出下面的 n 维状态后，就将剩下的 m 维分量丢弃。再从外界输入同样的 m 维分量，组合在一起恢复内部状态，作为下一次映射的输入。 注意到具有 $N^\\prime$ 形式的非自动系统也可以等价转换为自动系统。因此，不失一般性，我们只考虑非自动系统。 下面说明，当使用双曲吸引子进行锁存时，只有两种情况会发生：要么对噪声十分敏感，要么代价函数在 t 时刻对于 0 时刻的导数，将随 t 增加而指数下降。 4.1 分析为了锁存一位信息，希望将系统的活动 $a_t$ 限制在定义域的一个子集 $S$ 上。这样能区分两个状态：在 $S$ 内，和不在 $S$ 内。为了使 $a_t$ 保持在其中，动力系统可以将其放在一个吸引子的吸引盆（basin of attraction）中。（吸引子也可以是子流形或子空间的吸引子）。想要“擦除”这一位信息，系统将 $a_t$ 从吸引盆中推出，可能放进另一个吸引盆中。本节说明，如果吸引盆是双曲的（hyperbolic），或者可以转化为双曲的（比如周期稳定吸引子 periodic stable attractor），那么对 $t_0$ 输入的导数会迅速消失。 定义 1 ： $E$ 是映射 $M$ 的不动点，如果 $E = M(E)$ 定义 2 ： 不动点点集 $X$ 是可微映射 $M$ 的双曲吸引子，如果 $\\forall a \\in X, \\ M^\\prime(a)$ 的特征值的绝对值小于 1 。 吸引子可能包含一个点（固定点吸引子， fixed point attractor），有限个点（周期性吸引子， periodic attractor）或者无限个点（混沌吸引子， chaotic attractor）。 一个稳定的固定点吸引子，对于映射 $M$ 是双曲的；一个稳定的周期性的吸引子，设其周期为 $l$ ，则对于映射 $M^l$ 是双曲的。 RNN 的吸引子的种类取决于权值矩阵。对于 $a_t = W\\ \\tanh(a_{t-1})+u_t$ ，如果 $W$ 是对称的，且其最小特征值大于 -1 的话，那么其所有吸引子都是固定点。如果行列式小于 1 或者系统是线性且稳定的，那么只有在原点处有一个固定点吸引子。 以上关于吸引子的知识全没有接触过。翻译了一下。仅从直观上进行理解。 定义 3 ： 一个吸引子 $X$ 的吸引盆 $\\beta(X)$ ，指映射 $M$ 下收敛于 $X$ 的点集。即 $\\beta(x) = { a\\ :\\ \\forall \\epsilon, \\exists l, \\exists x \\in X \\text{ s.t. } ||M^l(a)|| \\lt \\epsilon}$ 定义 4 ： $\\Gamma(X)$ 是双曲吸引子 $X$ 吸引盆中的 reduced attracting set，如果满足 $\\forall l \\ge 1$ ， $(M^l)^\\prime(y)$ 的所有特征值小于 1。 根据定义有， $X \\subset \\Gamma(X) \\subset \\beta(X)$ 。 reduced 应该翻译成“剩余”还是“减小”？不太确定。这里只要求特征值小于 1 ，双曲吸引子要求特征绝对值小于 1 ，故双曲吸引子是 Gamma(X) 的子集。直觉上，特征值小于 1 可能对应上面“将其保持在吸引盆”中的要求。 定义 5 ： 一个系统可以鲁棒性地在 $t_0$ 锁存若干双曲吸引子中的一个吸引子 $X$ ，如果 $a_{t_0}$ 在 $X$ 对于定义自动系统的映射 $M$ 的 reduced attracting set 中。 对于非自动动力系统，只需 $a_t \\in \\Gamma(X) \\text{ for } t \\gt t_0$ 。接下来证明为什么使用 $\\Gamma(X)$ 来储存具有鲁棒性。 定理 1-3 及证明请查阅原文。最终证明了如果在 beta(X) 中，代表不确定性的球体会越来越大，因此输入的微小扰动可能将轨迹引导进入一个错误的吸引盆，即系统无法对抗噪声。相反，如果在 Gamma(X) 中，则能在输入中找到一个界，保证 a_t 一直在 X 中的点的特定距离内。因此是鲁棒的。见 Fig. 3 。 定理 4 ： 当输入 $u_t$ 使得系统在时间 0 后保持在 $X$ 上鲁棒时，随着 $t$ 趋近于无穷，$a_t$ 对 $a_0$ 的偏导趋近于 0 。 也就是说对抗噪声的代价是对过去事件的导数与近期事件相比会小很多。 4.2 对权重梯度的影响$$\\frac{\\partial C_t}{\\partial W} = \\sum_{\\tau \\le t} \\frac{\\partial C_t}{\\partial a_\\tau}\\frac{\\partial a_\\tau}{\\partial W} = \\sum_{\\tau \\le t} \\frac{\\partial C_t}{\\partial a_t}\\frac{\\partial a_t}{\\partial a_\\tau} \\frac{\\partial a_\\tau}{\\partial W}$$ 因此，相对于较近的事件，$\\tau \\ll t$ 的前两项的乘积较小，因此对最终的结果影响较小。也就是，即使可能存在一个 $W$ 使得 $a_\\tau$ 进入一个更好的吸引盆，但对 $W$ 的梯度不会反映这种可能性。 举例来说，假设 A ， B 两个系统顺次相接完成一项任务。且要求 B 使用 A 在 0 时刻检测到事件的信息，在遥远的 T 时刻使用该信息计算错误。（第 2 节定义的任务符合这个特征）。如果 B 训练不足，不能将 A 的结果锁存，那么 T 时刻的错误对 A 在 0 时刻产生的结果影响非常小。相反，如果 B 能够将信息储存很长时间，正确的梯度会被传播回去，但却迅速消失成为小值。因此， A 很难训练。 第 5 节 替代的方法 本节中给出了模拟退火等算法作为梯度下降的替代算法并在多个任务上测试了结果。每个任务上都有算法比反向传播更佳。 第 6 节 结论一个未进行讨论的点是类似的问题是否会在混沌吸引子中出现。 这个问题可能也会在深度前馈神经网络（feedforward network）中出现，因为 RNN 按时间展开就是一个共享权值的前馈神经网络。 本文研究并不意味着不能为特定任务训练神经网络，相反，如果有先验知识可以设置神经网络的权值共享和初值，利用起来会提升效果。比如在 latch problem 和 parity problem 中，先使用短序列进行训练可以让系统迅速进入正确的区域。","categories":[{"name":"计算机","slug":"计算机","permalink":"http://crvdgc.me/categories/计算机/"},{"name":"人工智能","slug":"计算机/人工智能","permalink":"http://crvdgc.me/categories/计算机/人工智能/"}],"tags":[{"name":"RNN","slug":"RNN","permalink":"http://crvdgc.me/tags/RNN/"},{"name":"长依赖","slug":"长依赖","permalink":"http://crvdgc.me/tags/长依赖/"}]},{"title":"编程解决《去月球》 To the Moon 记忆碎片小游戏","slug":"memento-solver","date":"2018-07-28T17:24:21.000Z","updated":"2018-07-30T07:20:16.155Z","comments":true,"path":"2018/07/29/memento-solver/","link":"","permalink":"http://crvdgc.me/2018/07/29/memento-solver/","excerpt":"","text":"引言记忆碎片（Memento）是游戏《去月球》（To the Moon）中的一个解谜小游戏。基本规则已在游戏中介绍。即通过点击按钮翻转某一行、列或者对角线，直至所有碎片都转成同一面。 这个解谜与成就/剧情分支无关，而且谜题设置比较简单，比较适合自己玩。谜题也非随机生成，答案都可以在网上找到。 兴趣使然地写了一个编程通用解法。在此介绍一下。 分析注意到同一位置进行任意偶数次变换都等价于不变，而奇数次变换等价于进行 1 次。为使总变换次数最少，只需决定每个位置是否进行变换即可。 其次，多个不同变换之间满足交换律和结合律，即任意改变变换之间的顺序不会影响最终的结果。 因此，每个解决方案，对应到将变换集合映射到 {进行，不进行} 集合的一个函数映射。若有 N 种可能的变换，则共有 2^N 种可能的解决方案。 可以使用二进制编码，宽度为 行数 + 列数 + 1 。每一位都对应着翻转行、列或对角线。该位为 1 代表进行变换，该位为 0 代表不进行变换。 接下来我们只需要枚举所有可能的解决方案，并将其中正确的挑选出来即可。 游戏中给出了最佳步数，因此可以作为加速搜索的方式，一旦解决方案中，变换的次数超过最佳步数，则跳过。这样，整个搜索空间大小从 2^N 减小到了 C(N, B) ，其中 B 是最佳变换次数， C 是组合数。 实现首先处理输入，我们将输入的图形转换为一个布尔矩阵。 12345rowNum = int(input('Row number: '))colNum = int(input('Col number: '))best = int(input('Best move: '))print(\"Input table, 1 for solved, 0 for unsolved\")table = [list(map(lambda x: True if int(x) == 1 else False, input().split())) for i in range(rowNum)] 接下来定义一些工具函数： 12345def check(): return all([all(row) for row in table])def flip(i, j): table[i][j] = False if table[i][j] else True 我们需要从解决方案中提取对应的行、列、对角线进行翻转： 12345678910111213def apply_solution(solution): for r in range(rowNum): if solution[r]: for c in range(colNum): flip(r, c) for c in range(colNum): if solution[rowNum+c]: for r in range(rowNum): flip(r, c) if solution[-1]: # diagnol, from left-bottom for i in range(min(rowNum, colNum)): flip(rowNum-1-i, i) 注意，对角线是从左下角开始的。 类似的，我们定义打印解决方案的函数： 123456789def print_solution(solution): for r in range(rowNum): if solution[r]: print('r%s' % r) for c in range(colNum): if solution[rowNum+c]: print('c%s' % c) if solution[-1]: print('d') 注意，编号从 0 开始，方向是从上到下、从左到右。 d 代表对角线。 主要过程是枚举整个解决方案空间： 1234567891011for solution in itertools.product([False, True], repeat=rowNum+colNum+1): if solution.count(True) &gt; best: continue apply_solution(solution) if check(): print_solution(solution) break else: apply_solution(solution)else: print('No answer for best move %s' % best) 首先，使用 itertools.product 产生所有的编码。 对于每一个编码，如果变换数大于最佳，则跳过当前。 如果找到了一个解，则打印并跳出，否则重新调用 apply_solution 函数将表格恢复原状态。 测试123456789101112131415161718192021Row number: 3Col number: 3Best move: 2Input table, 1 for solved, 0 for unsolved1 0 01 0 01 0 0c1c2Row number: 3Col number: 3Best move: 3Input table, 1 for solved, 0 for unsolved1 0 00 0 00 0 1r1c1d 附注itertools.product该函数产生一系列 iterable 的笛卡尔积（Cartesian product），如果指明了 repeat 关键字参数，则会将前面所有的 iterable 再和自己进行笛卡尔积。 全局依赖由于对角线的存在，每一次枚举行/列无法完全确定其他某个变换是否进行，因此没有进一步减小空间的机会。 但事实上，除了第一个谜题，游戏中每个谜题都包含对角线。因此，可以默认只在奇数编码中搜索。将对角线放在最后一位也有利于快速找到解决方案。 完整代码gist 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import itertoolsdef solve_memento(): rowNum = int(input('Row number: ')) colNum = int(input('Col number: ')) best = int(input('Best move: ')) print(\"Input table, 1 for solved, 0 for unsolved\") table = [list(map(lambda x: True if int(x) == 1 else False, input().split())) for i in range(rowNum)] def check(): return all([all(row) for row in table]) def flip(i, j): table[i][j] = False if table[i][j] else True def apply_solution(solution): for r in range(rowNum): if solution[r]: for c in range(colNum): flip(r, c) for c in range(colNum): if solution[rowNum+c]: for r in range(rowNum): flip(r, c) if solution[-1]: # diagnol, from left-bottom for i in range(min(rowNum, colNum)): flip(rowNum-1-i, i) def print_solution(solution): for r in range(rowNum): if solution[r]: print('r%s' % r) for c in range(colNum): if solution[rowNum+c]: print('c%s' % c) if solution[-1]: print('d') for solution in itertools.product([False, True], repeat=rowNum+colNum+1): if solution.count(True) &gt; best: continue apply_solution(solution) if check(): print_solution(solution) break else: apply_solution(solution) else: print('No answer for best move %s' % best)solve_memento()","categories":[{"name":"计算机","slug":"计算机","permalink":"http://crvdgc.me/categories/计算机/"},{"name":"杂谈","slug":"计算机/杂谈","permalink":"http://crvdgc.me/categories/计算机/杂谈/"}],"tags":[{"name":"游戏","slug":"游戏","permalink":"http://crvdgc.me/tags/游戏/"},{"name":"python","slug":"python","permalink":"http://crvdgc.me/tags/python/"},{"name":"兴趣","slug":"兴趣","permalink":"http://crvdgc.me/tags/兴趣/"}]},{"title":"PKD 电子梦评论 - Real Life / Exhibit Piece","slug":"electricDreams-01","date":"2018-07-25T07:22:46.000Z","updated":"2018-07-30T07:06:43.673Z","comments":true,"path":"2018/07/25/electricDreams-01/","link":"","permalink":"http://crvdgc.me/2018/07/25/electricDreams-01/","excerpt":"","text":"电子梦系列PKD 的作品，改编成为电视剧、电影的不在少数。但我还是对《电子梦》抱有独特期待的。不同于以往短篇改电影（《少数派报告》），长篇改电影（《银翼杀手》），长篇改电视剧（《高堡奇人》），《电子梦》将 PKD 的短篇改编成单元剧。每一篇小说独立，每一集剧也独立。短篇小说是最能体现科幻“点子小说”特点的载体。没有了人物和情节的负担，小说可以尽情发挥某个点子设定。身为 PKD 迷，怎么能错过这部剧呢？ 不过看了剧之后，感觉有几集水平真心一般。故从攒着买全集的钱里拨款，买了一本对应小说集，看看原作是否如此。本系列博客对应于每一集每一篇的评论。 &lt;&lt;&lt;&lt; 主要剧透预警 &gt;&gt;&gt;&gt; Quick RecapReal Life 剧集的主角有两位，一位是 Sarah ，未来世界的女同警察，一次针对警察的屠杀的幸存者，另一位是 George ，生活在现代的布鲁斯韦恩——拥有巨额财产却热衷于亲自行侠仗义打击犯罪。准确来讲，两个人共享思想和记忆，因此只是一个人的两个身份——问题在于，哪个身份是真的？ 两人分别在自己的世界中，通过 VR 设备进入到另一个世界和身份中。他们的爱人 Katie 名字相同，长相也相同，他们都在追查同一个姓名的罪犯。甚至来到同一家餐厅吃着同样的汉堡。区别在于，未来世界的生活“too good to be true”。在现代世界中， George 的妻子被罪犯报复残忍杀害，追捕罪犯也以失败告终。未来世界中， Sarah 不仅家庭美满，也成功抓到了罪犯。 两个 VR 项目都是捕捉潜意识中的愿望，将其转化为体验的。一个世界是以另一个世界为基础想象出来的。 如果 Sarah 的身份是虚假的，那么这个未来世界仅仅是一个“科幻世界”，里面有飞车、女同、幸福的家庭、成功抓捕到了罪犯，一切都是为了缓解丧妻之痛的幻想。 如果 George 的生活是虚假的，现实世界是 Sarah 的赎罪场，用自己的幻想折磨自己，以此发泄自己不配有这样幸福生活的自卑和愧疚——幸存者常有的心理障碍 survivor’s guilt，凭什么我能活下来。 对于 Sarah 的过去有清晰的记忆，而 George 的过去则需经人提醒才能慢慢想起。最终，他/她选择了 George 的生活，打碎了 VR 设备。未来世界的妻子看着自己的爱人迷失在 VR 世界中——原来这个世界才是真实的。 “为什么她选择了那样的人生？” “因为她想被自己的罪过惩罚，无论是真实的，还是虚构的。” Exhibit Piece根据 wiki 中的链接，本篇小说已经进入公共领域了。这里可以找到电子版和PDF版。 小说的主角 George Miller 是未来高压社会下的一名历史研究员，专门研究 20 世纪 50 年代的历史（本篇小说最初发表时间 1954 年）。为了研究的氛围，他平时身着那个年代的服装（在未来则属于奇装异服）。在一次和上司的冲突后， 他被展品——一个 50 年代生活的复制品——中的声音所吸引而进入了展品中。在那里，他回忆起了自己在其中的生活，一个妻子，两个孩子，有些令人担心的上司。 他感到困惑，因此找到了过去世界中的心理医生 Grunberg ，对方认为两套理论同样有说服力，但 George 却提出了第三个理论——两个世界都是真实的。医生建议他回到自己在世界中移动的点上，这样就能确定哪个世界是真实的。 他在那里见到了自己未来世界的同事和上司，他们认定 George 患了狂想症，威胁他要将他安乐死，并将展品拆除。 George 认为未来的高压社会没有什么值得生活的。与之相比，50 年代竟然成为了自由的黄金年代。 George 表示，展品实际上是一个时空门，他通过它回到了过去，而其他人无法回去。拆除展品只是毁坏了时空门，他将永远留在过去——正是他所希望的。 当 George 回到家中拿起报纸时，却发现上面写着，俄罗斯展示钴炸弹，全世界将面临毁灭。 究竟未来世界是他的幻想，还是他真的相信自己的展品是一个真实的世界，因为展品的拆除才出现了炸弹的新闻。抑或他真的回到了过去，炸弹的出现才是导致未来社会高压的原因。 评论改编剧中几乎没有留下什么，但两篇的主题都是“变换的现实”——一个 PKD 作品中经常出现的主题。如果我们对于现实的认知不能超过感官所及，那么又怎能区分“真实的现实”和“虚拟的现实”。《黑客帝国》中探讨过相同的主题，然而这一篇与《攻壳机动队》中更进一步，如果连思想和记忆都可以进行虚拟，不仅世界的真实性变得不可靠，连自我的真实性都无法决定了。 看过《银翼杀手》的同学一定会对此感到熟悉，仿生人通过虚假记忆不知道自己是仿生人，这是一个核心设定，《银翼杀手2049》中，仿生人知道自己是仿生人，且知道自己有虚假的记忆，一下将揭示虚假记忆所展现的力量削弱到几乎没有了。 PKD 自己也经常怀疑所处的世界是否为真实，一如他笔下的人物，他又无法最终抉择究竟哪种世界为真，因此作品的结局常常是含糊的。改编中给出了明确的答案，因此转变成了对虚拟现实这一万能许愿机的警告。 此外，在面对多个可能的真实时，人总是需要选择一种“自己的真实”，也即相信哪一个真实才是“真实的真实”。在选择的过程中，一种标准是，一定要活在真实中，也就是选择最像真实的那个真实。另一种标准是，只要活在自己最喜欢的真实即可。除了选中的真实以外，其他世界中的人都会觉得你在有意无意地“欺骗自己”。 虽然两个故事都没有展示，不过发现自己的选择错误也是一个有趣的点。比如剧中，与虚拟人物热情相拥，但却看到整个世界渐渐陷入黑暗，会怎么想呢？后悔自己的决定？还是坚持自己的选择？ PKD 提出了问题，意识到自己没有能力去回答，因此他提出了更多的问题。 《电子梦》的执行出品人 Ronald D. Moore （《太空堡垒卡拉狄加》、《星际迷航7》、《星际迷航8》、《星际迷航：下一代》）为本篇写了导读。他在其中表达了对今年来虚拟现实技术的关注，因此将 VR 项目引入到了故事中。实际上，他自己作为编剧写过一部探讨虚拟现实的电影 Virtuality 。 PKD 的时代已经出现了 VR 技术的先声，尽管 PKD 并没有明确的展示使用何种设备进入虚拟的现实。但他的作品无疑谈及了更广泛意义上的模拟现实（Simulated Reality），甚至不是模拟，而是另一种完全不同的现实。","categories":[{"name":"科幻","slug":"科幻","permalink":"http://crvdgc.me/categories/科幻/"},{"name":"评论","slug":"科幻/评论","permalink":"http://crvdgc.me/categories/科幻/评论/"}],"tags":[{"name":"pkd","slug":"pkd","permalink":"http://crvdgc.me/tags/pkd/"},{"name":"剧集","slug":"剧集","permalink":"http://crvdgc.me/tags/剧集/"},{"name":"cyberpunk","slug":"cyberpunk","permalink":"http://crvdgc.me/tags/cyberpunk/"},{"name":"虚拟现实","slug":"虚拟现实","permalink":"http://crvdgc.me/tags/虚拟现实/"}]}]}